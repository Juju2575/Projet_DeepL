{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchtext==0.10.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.11.0 torchtext==0.12.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.functional import to_map_style_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/news-article-categories-clean.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66936"
      ]
     },
     "execution_count": 960,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "data['tok_body'] = data.body.apply(lambda x: tokenizer(x))\n",
    "\n",
    "vocab = build_vocab_from_iterator(data['tok_body'], min_freq=1, specials=[\"<UNK>\"])\n",
    "\n",
    "vocab.set_default_index(vocab[\"<UNK>\"])\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cat\"] = pd.Categorical(data.category)\n",
    "data['cat_code'] = data.cat.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"body_tok\"] = data[\"body\"].apply(lambda x: vocab(tokenizer(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"body_max_len\"] = data[\"body_tok\"].apply(lambda x: x+([0]* (max_words-len(x))) if len(x)<max_words else x[:max_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>tok_body</th>\n",
       "      <th>cat</th>\n",
       "      <th>cat_code</th>\n",
       "      <th>body_tok</th>\n",
       "      <th>body_max_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARTS &amp; CULTURE</td>\n",
       "      <td>Modeling Agencies Enabled Sexual Predators For...</td>\n",
       "      <td>october carolyn kramer received disturbing pho...</td>\n",
       "      <td>[october, carolyn, kramer, received, disturbin...</td>\n",
       "      <td>ARTS &amp; CULTURE</td>\n",
       "      <td>0</td>\n",
       "      <td>[1298, 8062, 5640, 555, 2648, 404, 151, 120, 4...</td>\n",
       "      <td>[1298, 8062, 5640, 555, 2648, 404, 151, 120, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARTS &amp; CULTURE</td>\n",
       "      <td>Actor Jeff Hiller Talks “Bright Colors And Bol...</td>\n",
       "      <td>week talked actor jeff hiller hit broadway pla...</td>\n",
       "      <td>[week, talked, actor, jeff, hiller, hit, broad...</td>\n",
       "      <td>ARTS &amp; CULTURE</td>\n",
       "      <td>0</td>\n",
       "      <td>[58, 1515, 575, 1825, 23777, 531, 1370, 161, 2...</td>\n",
       "      <td>[58, 1515, 575, 1825, 23777, 531, 1370, 161, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARTS &amp; CULTURE</td>\n",
       "      <td>New Yorker Cover Puts Trump 'In The Hole' Afte...</td>\n",
       "      <td>new yorker taking president donald trump asked...</td>\n",
       "      <td>[new, yorker, taking, president, donald, trump...</td>\n",
       "      <td>ARTS &amp; CULTURE</td>\n",
       "      <td>0</td>\n",
       "      <td>[8, 2833, 366, 34, 174, 12, 199, 9, 1646, 613,...</td>\n",
       "      <td>[8, 2833, 366, 34, 174, 12, 199, 9, 1646, 613,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARTS &amp; CULTURE</td>\n",
       "      <td>Man Surprises Girlfriend By Drawing Them In Di...</td>\n",
       "      <td>kellen hickey year old life hudson wisconsin g...</td>\n",
       "      <td>[kellen, hickey, year, old, life, hudson, wisc...</td>\n",
       "      <td>ARTS &amp; CULTURE</td>\n",
       "      <td>0</td>\n",
       "      <td>[37533, 10231, 3, 90, 24, 8104, 3072, 1278, 84...</td>\n",
       "      <td>[37533, 10231, 3, 90, 24, 8104, 3072, 1278, 84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARTS &amp; CULTURE</td>\n",
       "      <td>This Artist Gives Renaissance-Style Sculptures...</td>\n",
       "      <td>something combining traditional uptight look r...</td>\n",
       "      <td>[something, combining, traditional, uptight, l...</td>\n",
       "      <td>ARTS &amp; CULTURE</td>\n",
       "      <td>0</td>\n",
       "      <td>[81, 5485, 941, 33242, 95, 6082, 799, 933, 25,...</td>\n",
       "      <td>[81, 5485, 941, 33242, 95, 6082, 799, 933, 25,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                                              title  \\\n",
       "0  ARTS & CULTURE  Modeling Agencies Enabled Sexual Predators For...   \n",
       "1  ARTS & CULTURE  Actor Jeff Hiller Talks “Bright Colors And Bol...   \n",
       "2  ARTS & CULTURE  New Yorker Cover Puts Trump 'In The Hole' Afte...   \n",
       "3  ARTS & CULTURE  Man Surprises Girlfriend By Drawing Them In Di...   \n",
       "4  ARTS & CULTURE  This Artist Gives Renaissance-Style Sculptures...   \n",
       "\n",
       "                                                body  \\\n",
       "0  october carolyn kramer received disturbing pho...   \n",
       "1  week talked actor jeff hiller hit broadway pla...   \n",
       "2  new yorker taking president donald trump asked...   \n",
       "3  kellen hickey year old life hudson wisconsin g...   \n",
       "4  something combining traditional uptight look r...   \n",
       "\n",
       "                                            tok_body             cat  \\\n",
       "0  [october, carolyn, kramer, received, disturbin...  ARTS & CULTURE   \n",
       "1  [week, talked, actor, jeff, hiller, hit, broad...  ARTS & CULTURE   \n",
       "2  [new, yorker, taking, president, donald, trump...  ARTS & CULTURE   \n",
       "3  [kellen, hickey, year, old, life, hudson, wisc...  ARTS & CULTURE   \n",
       "4  [something, combining, traditional, uptight, l...  ARTS & CULTURE   \n",
       "\n",
       "   cat_code                                           body_tok  \\\n",
       "0         0  [1298, 8062, 5640, 555, 2648, 404, 151, 120, 4...   \n",
       "1         0  [58, 1515, 575, 1825, 23777, 531, 1370, 161, 2...   \n",
       "2         0  [8, 2833, 366, 34, 174, 12, 199, 9, 1646, 613,...   \n",
       "3         0  [37533, 10231, 3, 90, 24, 8104, 3072, 1278, 84...   \n",
       "4         0  [81, 5485, 941, 33242, 95, 6082, 799, 933, 25,...   \n",
       "\n",
       "                                        body_max_len  \n",
       "0  [1298, 8062, 5640, 555, 2648, 404, 151, 120, 4...  \n",
       "1  [58, 1515, 575, 1825, 23777, 531, 1370, 161, 2...  \n",
       "2  [8, 2833, 366, 34, 174, 12, 199, 9, 1646, 613,...  \n",
       "3  [37533, 10231, 3, 90, 24, 8104, 3072, 1278, 84...  \n",
       "4  [81, 5485, 941, 33242, 95, 6082, 799, 933, 25,...  "
      ]
     },
     "execution_count": 964,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6871 entries, 0 to 6870\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   category      6871 non-null   object  \n",
      " 1   title         6871 non-null   object  \n",
      " 2   body          6871 non-null   object  \n",
      " 3   tok_body      6871 non-null   object  \n",
      " 4   cat           6871 non-null   category\n",
      " 5   cat_code      6871 non-null   int8    \n",
      " 6   body_tok      6871 non-null   object  \n",
      " 7   body_max_len  6871 non-null   object  \n",
      "dtypes: category(1), int8(1), object(6)\n",
      "memory usage: 336.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data_sans_na = data.dropna()\n",
    "data_sans_na.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Target Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_classes = [\"ART & CULTURE\",\"BUSINESS\",\"COMEDY\",\"CRIME\",\"EDUCATION\",\"ENTERTAINMENT\",\"ENVIRONMENT\",\"MEDIA\",\"POLITICS\",\"RELIGION\",\"SCIENCE\",\"SPORTS\",\"TECH\",\"WOMEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_classes_int = [i for i in range(14)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_sans_na.drop([\"category\", \"cat_code\", \"cat\"], axis =1)\n",
    "y = data_sans_na[\"cat_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>tok_body</th>\n",
       "      <th>body_tok</th>\n",
       "      <th>body_max_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modeling Agencies Enabled Sexual Predators For...</td>\n",
       "      <td>october carolyn kramer received disturbing pho...</td>\n",
       "      <td>[october, carolyn, kramer, received, disturbin...</td>\n",
       "      <td>[1298, 8062, 5640, 555, 2648, 404, 151, 120, 4...</td>\n",
       "      <td>[1298, 8062, 5640, 555, 2648, 404, 151, 120, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor Jeff Hiller Talks “Bright Colors And Bol...</td>\n",
       "      <td>week talked actor jeff hiller hit broadway pla...</td>\n",
       "      <td>[week, talked, actor, jeff, hiller, hit, broad...</td>\n",
       "      <td>[58, 1515, 575, 1825, 23777, 531, 1370, 161, 2...</td>\n",
       "      <td>[58, 1515, 575, 1825, 23777, 531, 1370, 161, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Yorker Cover Puts Trump 'In The Hole' Afte...</td>\n",
       "      <td>new yorker taking president donald trump asked...</td>\n",
       "      <td>[new, yorker, taking, president, donald, trump...</td>\n",
       "      <td>[8, 2833, 366, 34, 174, 12, 199, 9, 1646, 613,...</td>\n",
       "      <td>[8, 2833, 366, 34, 174, 12, 199, 9, 1646, 613,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man Surprises Girlfriend By Drawing Them In Di...</td>\n",
       "      <td>kellen hickey year old life hudson wisconsin g...</td>\n",
       "      <td>[kellen, hickey, year, old, life, hudson, wisc...</td>\n",
       "      <td>[37533, 10231, 3, 90, 24, 8104, 3072, 1278, 84...</td>\n",
       "      <td>[37533, 10231, 3, 90, 24, 8104, 3072, 1278, 84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This Artist Gives Renaissance-Style Sculptures...</td>\n",
       "      <td>something combining traditional uptight look r...</td>\n",
       "      <td>[something, combining, traditional, uptight, l...</td>\n",
       "      <td>[81, 5485, 941, 33242, 95, 6082, 799, 933, 25,...</td>\n",
       "      <td>[81, 5485, 941, 33242, 95, 6082, 799, 933, 25,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Modeling Agencies Enabled Sexual Predators For...   \n",
       "1  Actor Jeff Hiller Talks “Bright Colors And Bol...   \n",
       "2  New Yorker Cover Puts Trump 'In The Hole' Afte...   \n",
       "3  Man Surprises Girlfriend By Drawing Them In Di...   \n",
       "4  This Artist Gives Renaissance-Style Sculptures...   \n",
       "\n",
       "                                                body  \\\n",
       "0  october carolyn kramer received disturbing pho...   \n",
       "1  week talked actor jeff hiller hit broadway pla...   \n",
       "2  new yorker taking president donald trump asked...   \n",
       "3  kellen hickey year old life hudson wisconsin g...   \n",
       "4  something combining traditional uptight look r...   \n",
       "\n",
       "                                            tok_body  \\\n",
       "0  [october, carolyn, kramer, received, disturbin...   \n",
       "1  [week, talked, actor, jeff, hiller, hit, broad...   \n",
       "2  [new, yorker, taking, president, donald, trump...   \n",
       "3  [kellen, hickey, year, old, life, hudson, wisc...   \n",
       "4  [something, combining, traditional, uptight, l...   \n",
       "\n",
       "                                            body_tok  \\\n",
       "0  [1298, 8062, 5640, 555, 2648, 404, 151, 120, 4...   \n",
       "1  [58, 1515, 575, 1825, 23777, 531, 1370, 161, 2...   \n",
       "2  [8, 2833, 366, 34, 174, 12, 199, 9, 1646, 613,...   \n",
       "3  [37533, 10231, 3, 90, 24, 8104, 3072, 1278, 84...   \n",
       "4  [81, 5485, 941, 33242, 95, 6082, 799, 933, 25,...   \n",
       "\n",
       "                                        body_max_len  \n",
       "0  [1298, 8062, 5640, 555, 2648, 404, 151, 120, 4...  \n",
       "1  [58, 1515, 575, 1825, 23777, 531, 1370, 161, 2...  \n",
       "2  [8, 2833, 366, 34, 174, 12, 199, 9, 1646, 613,...  \n",
       "3  [37533, 10231, 3, 90, 24, 8104, 3072, 1278, 84...  \n",
       "4  [81, 5485, 941, 33242, 95, 6082, 799, 933, 25,...  "
      ]
     },
     "execution_count": 969,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: cat_code, dtype: int8"
      ]
     },
     "execution_count": 970,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Vectorize Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vectorize_batch(batch):\n",
    "#     Y = []\n",
    "#     X = []\n",
    "#     for item in batch:\n",
    "#         Y.append(item[\"label\"])\n",
    "#         text = item[\"text\"]\n",
    "#         text_tok = [vocab(tokenizer(text)) for text in text]\n",
    "#         text = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in text_tok] ## Bringing all samples to max_words length.\n",
    "#         X.append(text)\n",
    "#     return torch.tensor(X,dtype=torch.int32), torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_words = 25\n",
    "\n",
    "# def vectorize_batch(batch):\n",
    "#     Y, X = list(zip(*batch))\n",
    "#     X = [vocab(tokenizer(text)) for text in X]\n",
    "#     X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X]\n",
    "#     return torch.tensor(X,dtype=torch.int32), torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_batch(batch):\n",
    "    # print(\"batch type :\", type(batch))\n",
    "    # print(len(batch))\n",
    "    # print(batch[0])\n",
    "    # print(len(batch[0]))\n",
    "    Y = tuple(map(lambda x: x[\"label\"], batch))\n",
    "    X = tuple(map(lambda x: x[\"text\"], batch))\n",
    "    X_t = torch.tensor(X,dtype=torch.long)\n",
    "    Y_t = torch.tensor(Y, dtype=torch.long)\n",
    "    # print(X_t)\n",
    "    # print(Y_t)\n",
    "    #Y_t = Y_t.unsqueeze(1)\n",
    "    return X_t, Y_t\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple1 = tuple(map(lambda x: x[\"label\"], liste))\n",
    "tuple2 = tuple(map(lambda x: x[\"text\"], liste))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir une classe pour transformer un Dataframe en Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        text = row['body_max_len']\n",
    "        label = row['cat_code']\n",
    "        return {'label': label, 'text': text}\n",
    "\n",
    "# Créer une instance de la classe Dataset personnalisée\n",
    "train_dataset = CustomDataset(train)\n",
    "test_dataset = CustomDataset(test)\n",
    "\n",
    "train_dataset, test_dataset  = to_map_style_dataset(train_dataset), to_map_style_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = train[[\"body_max_len\", \"cat_code\"]]\n",
    "# test_dataset= test[[\"body_max_len\", \"cat_code\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1024, collate_fn= vectorize_batch, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset , batch_size=1024, collate_fn=vectorize_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 100]) torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "for X, Y in train_loader:\n",
    "    print(X.shape, Y.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paramètres du modèle\n",
    "EMBED_LEN = 50\n",
    "HIDDEN_SIZE = 50\n",
    "OUTPUT_SIZE = len(target_classes_int)\n",
    "N_LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classe pour le modèle RNN\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=EMBED_LEN)\n",
    "        self.rnn = nn.RNN(input_size=EMBED_LEN, hidden_size=HIDDEN_SIZE, num_layers=N_LAYERS, batch_first=True)\n",
    "        self.linear = nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "\n",
    "    def forward(self, X_batch):\n",
    "        embeddings = self.embedding_layer(X_batch)\n",
    "        output, hidden = self.rnn(embeddings, torch.randn(N_LAYERS, len(X_batch), HIDDEN_SIZE))\n",
    "        return self.linear(output[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNClassifier(\n",
       "  (embedding_layer): Embedding(66936, 50)\n",
       "  (rnn): RNN(50, 50, batch_first=True)\n",
       "  (linear): Linear(in_features=50, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 983,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_classifier = RNNClassifier()\n",
    "\n",
    "rnn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer : Embedding(66936, 50)\n",
      "Parameters : \n",
      "torch.Size([66936, 50])\n",
      "\n",
      "Layer : RNN(50, 50, batch_first=True)\n",
      "Parameters : \n",
      "torch.Size([50, 50])\n",
      "torch.Size([50, 50])\n",
      "torch.Size([50])\n",
      "torch.Size([50])\n",
      "\n",
      "Layer : Linear(in_features=50, out_features=14, bias=True)\n",
      "Parameters : \n",
      "torch.Size([14, 50])\n",
      "torch.Size([14])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for layer in rnn_classifier.children():\n",
    "    print(\"Layer : {}\".format(layer))\n",
    "    print(\"Parameters : \")\n",
    "    for param in layer.parameters():\n",
    "        print(param.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 14])"
      ]
     },
     "execution_count": 985,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = rnn_classifier(torch.randint(0, len(vocab), (1024, max_words)))\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gc\n",
    "\n",
    "def calc_val_loss_and_accuracy(model, loss_fn, val_loader):\n",
    "    with torch.no_grad():\n",
    "        Y_shuffled, Y_preds, losses = [],[],[]\n",
    "        for X, Y in val_loader:\n",
    "            preds = model(X)\n",
    "            loss = loss_fn(preds, Y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            Y_shuffled.append(Y)\n",
    "            Y_preds.append(preds.argmax(dim=-1))\n",
    "\n",
    "        Y_shuffled = torch.cat(Y_shuffled)\n",
    "        Y_preds = torch.cat(Y_preds)\n",
    "\n",
    "        print(\"Valid Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
    "        print(\"Valid Acc  : {:.3f}\".format(accuracy_score(Y_shuffled.detach().numpy(), Y_preds.detach().numpy())))\n",
    "\n",
    "\n",
    "def train_model(model, loss_fn, optimizer, train_loader, val_loader, epochs=10):\n",
    "    for i in range(1, epochs+1):\n",
    "        losses = []\n",
    "        for X, Y in tqdm(train_loader):\n",
    "            Y_preds = model(X)\n",
    "\n",
    "            loss = loss_fn(Y_preds, Y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
    "        calc_val_loss_and_accuracy(model, loss_fn, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = rnn_classifier\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# for X, Y in train_loader:\n",
    "#     Y_preds = model(X)\n",
    "#     print(Y_preds.type)\n",
    "#     print(Y.type())\n",
    "#     loss = loss_fn(Y_preds, Y)\n",
    "#     # losses.append(loss.item())\n",
    "\n",
    "#     # optimizer.zero_grad()\n",
    "#     # loss.backward()\n",
    "#     # optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of target with class indices\n",
    "# loss = nn.CrossEntropyLoss()\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# print(input)\n",
    "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "# print(target)\n",
    "# output = loss(input, target)\n",
    "# output.backward()\n",
    "# print(output)\n",
    "\n",
    "# # Example of target with class probabilities\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.randn(3, 5).softmax(dim=1)\n",
    "# output = loss(input, target)\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "epochs = 15\n",
    "learning_rate = 1e-3\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "rnn_classifier = RNNClassifier()\n",
    "optimizer = Adam(rnn_classifier.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.660\n",
      "Valid Loss : 2.636\n",
      "Valid Acc  : 0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.604\n",
      "Valid Loss : 2.606\n",
      "Valid Acc  : 0.097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.570\n",
      "Valid Loss : 2.588\n",
      "Valid Acc  : 0.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.542\n",
      "Valid Loss : 2.576\n",
      "Valid Acc  : 0.114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.519\n",
      "Valid Loss : 2.564\n",
      "Valid Acc  : 0.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.489\n",
      "Valid Loss : 2.551\n",
      "Valid Acc  : 0.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.472\n",
      "Valid Loss : 2.542\n",
      "Valid Acc  : 0.142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.458\n",
      "Valid Loss : 2.539\n",
      "Valid Acc  : 0.157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.440\n",
      "Valid Loss : 2.536\n",
      "Valid Acc  : 0.160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.426\n",
      "Valid Loss : 2.535\n",
      "Valid Acc  : 0.161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.414\n",
      "Valid Loss : 2.534\n",
      "Valid Acc  : 0.160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.404\n",
      "Valid Loss : 2.533\n",
      "Valid Acc  : 0.159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.393\n",
      "Valid Loss : 2.533\n",
      "Valid Acc  : 0.159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.380\n",
      "Valid Loss : 2.533\n",
      "Valid Acc  : 0.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.374\n",
      "Valid Loss : 2.533\n",
      "Valid Acc  : 0.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(rnn_classifier, loss_fn, optimizer, train_loader, test_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakePredictions(model, loader):\n",
    "    Y_shuffled, Y_preds = [], []\n",
    "    for X, Y in loader:\n",
    "        preds = model(X)\n",
    "        Y_preds.append(preds)\n",
    "        Y_shuffled.append(Y)\n",
    "    gc.collect()\n",
    "    Y_preds, Y_shuffled = torch.cat(Y_preds), torch.cat(Y_shuffled)\n",
    "\n",
    "    return Y_shuffled.detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).detach().numpy()\n",
    "\n",
    "Y_actual, Y_preds = MakePredictions(rnn_classifier, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.15636363636363637\n",
      "\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "ART & CULTURE       0.15      0.70      0.25       193\n",
      "     BUSINESS       0.06      0.02      0.03        91\n",
      "       COMEDY       0.32      0.69      0.43        71\n",
      "        CRIME       0.00      0.00      0.00        67\n",
      "    EDUCATION       0.13      0.15      0.14       109\n",
      "ENTERTAINMENT       0.12      0.02      0.04        92\n",
      "  ENVIRONMENT       0.08      0.01      0.02        85\n",
      "        MEDIA       0.00      0.00      0.00        66\n",
      "     POLITICS       0.00      0.00      0.00       112\n",
      "     RELIGION       0.05      0.02      0.03        90\n",
      "      SCIENCE       0.14      0.01      0.02        87\n",
      "       SPORTS       0.00      0.00      0.00       108\n",
      "         TECH       0.09      0.02      0.03       101\n",
      "        WOMEN       0.09      0.05      0.06       103\n",
      "\n",
      "     accuracy                           0.16      1375\n",
      "    macro avg       0.09      0.12      0.08      1375\n",
      " weighted avg       0.09      0.16      0.09      1375\n",
      "\n",
      "\n",
      "Confusion Matrix : \n",
      "[[135   4  11   2  15   3   0   0   1   6   2   0   2  12]\n",
      " [ 66   2   1   0   3   1   3   0   2   7   0   2   3   1]\n",
      " [ 15   0  49   0   2   0   0   0   0   2   0   2   0   1]\n",
      " [ 45   1   1   0   8   2   0   0   1   3   0   0   0   6]\n",
      " [ 73   2   1   0  16   0   0   0   3   4   1   2   2   5]\n",
      " [ 48   2  20   0   8   2   4   0   0   3   0   3   1   1]\n",
      " [ 38   3  28   0   7   0   1   0   0   1   1   2   2   2]\n",
      " [ 47   1   5   0   4   2   1   0   1   2   0   1   1   1]\n",
      " [ 86   4   0   0  11   1   1   0   0   2   0   1   2   4]\n",
      " [ 58   4   3   0  14   0   0   0   0   2   1   2   0   6]\n",
      " [ 60   1   6   0   8   0   0   0   0   3   1   1   1   6]\n",
      " [ 68   0  13   1  13   2   0   0   2   5   1   0   2   1]\n",
      " [ 65   3  12   1   6   1   1   0   3   3   0   1   2   3]\n",
      " [ 73   4   5   2   5   2   1   0   0   1   0   0   5   5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julie\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\julie\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\julie\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Test Accuracy : {}\".format(accuracy_score(Y_actual, Y_preds)))\n",
    "print(\"\\nClassification Report : \")\n",
    "print(classification_report(Y_actual, Y_preds, target_names=target_classes))\n",
    "print(\"\\nConfusion Matrix : \")\n",
    "print(confusion_matrix(Y_actual, Y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc19f1aca79640f29e4f4d7df31b19f58d3c80ef392b15c9e85b5fe0f1809e47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
